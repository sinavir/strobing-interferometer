{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Stroboscopic imaging system","text":"<p>This is the documentation of the stroboscopic imaging system. It includes all the necessary knowledge to operate the system.</p>"},{"location":"#contact","title":"Contact","text":"<p>If you have any question please do not hesitate to send an email to us (the two masters who did this project):</p> <ul> <li>Maurice Debray: <code>maurice.debray (at) ens.fr</code></li> <li>TODO email fred</li> </ul>"},{"location":"getting_started/","title":"Getting started","text":"<p>This is a recipe on how to make an acquisition. We recommend reading optical setup presentation page before trying to use the setup.</p>"},{"location":"getting_started/#load-the-membrane","title":"Load the membrane","text":"<p>Load the membrane and turn on the laser (follow more detailed instruction provided in the experimental setup section)</p>"},{"location":"getting_started/#start-the-software","title":"Start the software","text":"<ol> <li>On the QMPL desktop start LabOne and open jupyter notebook provided at    <code>TODO</code> in the <code>work</code> Conda environment (this is the usual environment).</li> <li>Launch the ThorCam software and open the pinhole camera <code>TODO SN pinhole camera</code></li> <li>Run the first cell of the notebook to initialize all the code (some initial    settings are tunable. Refer to the reference here for more details)</li> <li>Fill the folder to store the data in the next cell</li> </ol> <p>Warning</p> <p>Don't try to open the imaging camera (TODO serial number) with the ThorCam software else your acquisition might fail.</p>"},{"location":"getting_started/#find-the-eigen-frequency-of-the-membrane","title":"Find the eigen-frequency of the membrane","text":"<p>First check and align the defect of the membrane with the pinhole (more on this here).</p> <p>Then use LabOne to find the eigen-modes of the membrane</p>"},{"location":"getting_started/#acquisition","title":"Acquisition","text":"<p>The acquisition process is detailed here and the file format is documented here.</p>"},{"location":"getting_started/#calibration-data","title":"Calibration data","text":"<ul> <li>Turn off the drive and let the membrane ringdown.</li> <li>Run the calibration cell.</li> </ul>"},{"location":"getting_started/#mode-shape","title":"Mode shape","text":"<ul> <li>Turn on the drive and find back the mode (you shouldn't need to do a sweep).</li> <li>Run the acquisition cell.</li> </ul>"},{"location":"getting_started/#analyze-the-data","title":"Analyze the data","text":"<p>Analyze the data in a separate notebook not to clutter the acquisition notebook. Below is a example of what you can do. For more explanation see here.</p> <pre><code>\"\"\"\nTODO sample analysis script\n\"\"\"\n</code></pre>"},{"location":"membrane_holder/assembly_and_loading/","title":"Assembly of the holder","text":""},{"location":"optical_setup/alignment_FAQ/","title":"Alignment frequently asked questions","text":""},{"location":"optical_setup/alignment_FAQ/#why-is-the-imaging-setup-tilted","title":"Why is the imaging setup tilted","text":"<p>We tilted it to get rid of reflections on the vacuum chamber glass.</p> <p>Note</p> <p>The main beam-splitter in the black box is also tilted. This is because we observed also less parasitic reflections doing so.</p>"},{"location":"optical_setup/alignment_FAQ/#can-i-move-this-lens-or-mirror","title":"Can I move this lens or mirror","text":"<p>Only of you know what you are doing. The hardest part to align are (in decreasing difficulty):</p> <ol> <li> <p>Pinhole + Photo-diode + Pinhole Camera: This part isn't so tricky but     can take a long time to inexperienced hands. Please follow the protocol     here to realign.</p> <p>Warning</p> <p>Moving the lenses on the pinhole alignment might be tricky. We don't now to what extend the cropped beam (by the pinhole) move when doing so and if it remains in the sensitive region of the photo-diode. Anyway, if you feel you lost some signal while doing so, move slightly the photo-diode to get signal back. Don't move the camera and the pinhole in this case, else you are good to follow the protocol here.</p> </li> <li> <p>Laser beam Getting the laser beam hitting the membrane in a nice way can     take time. If you don't see fringes it means the     you are in the situation depicted in the following figure.</p> <p>TODO schema</p> </li> <li> <p>Imaging setup You can move this part of the setup. It's not difficult to align     if you understand how a camera+objective setups works. We encourage you to move the mirror between     the objective and the camera to tune your image.</p> </li> </ol>"},{"location":"optical_setup/alignment_FAQ/#too-much-fringes-on-the-membrane","title":"Too much fringes on the membrane","text":"<p>The membrane isn't parallel to the back-glass slab. Please read the documentation here to correct that.</p>"},{"location":"optical_setup/pinhole_alignment/","title":"Pinhole alignment protocol","text":"<p>TODO schema</p>"},{"location":"optical_setup/pinhole_alignment/#light-protocol","title":"Light protocol","text":"<p>This protocol is quick. You should do it each time you load a new membrane.</p> <ol> <li> <p>Tune the \"pinhole\" mirror to see the defect on the center of the camera. This    should correspond to the middle of the pinhole.</p> </li> <li> <p>Optional Slightly move the photo-diode to get maximum power. If you lose the photo-diode position it can be hard to get back to it.</p> </li> </ol>"},{"location":"optical_setup/pinhole_alignment/#heavy-protocol","title":"Heavy protocol","text":"<p>This protocol is longer to implement but definitely doable. Aligning a cavity is highly likely much harder. Apply this protocol if you're not confident about the location of the pinhole.</p> <ol> <li> <p>Examine the setup</p> </li> <li> <p>Remove the pinhole and move the camera so the sensor lands at the place the pinhole was before.</p> </li> <li> <p>Tune the focus lens and the mirror to center the defect on the camera.</p> </li> <li> <p>move the camera back to give some space for the pinhole</p> </li> <li> <p>Draw a cross in ThorCam software on the defect</p> </li> <li> <p>Put the pinhole on the optical path such that you see on the camera the    bright spot from the pinhole at the exact location of the defect (use the cross drawn at step 5) to help</p> </li> <li> <p>Put back the camera as its original place and center the defect. You can also mark the coordinates of the pinhole on a paper you keep preciously.</p> </li> <li> <p>Put the photo-diode back after the pinhole. It can take a long time to get back some signal since the sensitive region of the photo-diode is small.</p> </li> </ol>"},{"location":"optical_setup/presentation/","title":"Optical setup presentation","text":"<p>TODO Schema</p>"},{"location":"optical_setup/presentation/#the-inteferometric-setup","title":"The inteferometric setup","text":""},{"location":"optical_setup/presentation/#the-pinhole-trick","title":"The pinhole trick","text":"<p>To be able to find the mode we looked</p>"},{"location":"programs/acquisition_tutorial/","title":"Acquisition explanations","text":"<p>TODO</p>"},{"location":"programs/analysis/","title":"Analysis script explanations","text":"<p>TODO</p>"},{"location":"programs/file_format/","title":"File format","text":"<p>The python library use the <code>hdf5</code> file format to store one acquisition (calibration + strobed videos).</p> <p>The hdf5 structure is as follow</p> <pre><code>TODO batter representtion of attributes\n\n\nfile.h5  (2 objects, 6 attributes)\n\u2502   \u251c\u2500\u2500 duty cycle strobe (%)  5\n\u2502   \u251c\u2500\u2500 exposure_time_us  15000\n\u2502   \u251c\u2500\u2500 frame_shape  [1080 1440]\n\u2502   \u251c\u2500\u2500 laser  L785\n\u2502   \u251c\u2500\u2500 membrane  topo\n\u2502   \u2514\u2500\u2500 sensing region  1\n\u251c\u2500\u2500 bias calibration  (3 objects)\n\u2502   \u251c\u2500\u2500 biases  (100,), float64\n\u2502   \u251c\u2500\u2500 photos  (100, 1080, 1440), float64  # Average of the below videos\n\u2502   \u2514\u2500\u2500 videos  (100, 10, 1080, 1440), uint16\n\u2514\u2500\u2500 stroboscopic  (10 objects, 4 attributes)\n    \u251c\u2500\u2500 acquisition time  -284.05384135246277\n    \u251c\u2500\u2500 drive amplitude  0.04999580380099335\n    \u251c\u2500\u2500 drive frequency  1307205.9200001007\n    \u251c\u2500\u2500 strobe detuning  0.0799998992588371\n    \u251c\u2500\u2500 video0  (288, 1080, 1440), uint16\n    \u2502   \u251c\u2500\u2500 bias(V)  -2.7222222222222223\n    \u2502   \u2514\u2500\u2500 fps  20.0\n    \u251c\u2500\u2500 video1  (288, 1080, 1440), uint16\n    \u2502   \u251c\u2500\u2500 bias(V)  -2.166666666666667\n    \u2502   \u2514\u2500\u2500 fps  20.0\n    ...\n</code></pre> <p>You can furthermore explore the file structure with this tool: https://myhdf5.hdfgroup.org/ (It works well even with the 13 gigabytes files the acquisition script produce).</p> <p>To access the raw data, use the <code>h5py</code> library documented here: https://docs.h5py.org/.</p> <p>The analysis tools (to get nice plots of the membrane) are documented in the reference. A more step by step tutorial is provided in analysis script explanations.</p>"},{"location":"programs/python_module_reference/","title":"Reference","text":""},{"location":"programs/python_module_reference/#strobing_interferometer.analysis.StdAnalysis","title":"<code>StdAnalysis</code>","text":"Source code in <code>strobing_interferometer/analysis.py</code> <pre><code>class StdAnalysis:\n\n    file_dependent_properties = [\n        \"calibration_biases\",\n        \"calibration_values\",\n    ]  # Properties that depend on the hdf5 file\n\n    def __init__(self, file):\n        self._file = file\n\n    def file_open(self):\n        return self._file\n\n    def file_open_or_fail(self):\n        if not self.file_open():\n            raise IOError(\"HDF5 file closed too early\")\n\n    def get_calibration_photos(self):\n        self.file_open_or_fail()\n        return self._file[\"bias calibration\"][\"photos\"][...]\n\n    def get_calibration_biases(self):\n        self.file_open_or_fail()\n        return self._file[\"bias calibration\"][\"biases\"][...]\n\n    def smooth_calibration(self, window=np.array([0.1, 0.25, 0.3, 0.25, 0.1])):\n        \"\"\"\n        Smooth the calibration data points\n        \"\"\"\n        if len(window.shape) &gt; 1:\n            raise ValueError(\"Smoothing kernel should be 1-dimensional\")\n\n        photos = self.get_calibration_photos()\n        biases = self.get_calibration_biases()\n        smoothed = np.apply_along_axis(\n            lambda x: np.convolve(window, x, mode=\"valid\"), axis=0, arr=photos\n        )\n        offset = window.size // 2  # number of values missing on each side\n\n        self.calibration_biases = biases[offset:-offset]\n        self.calibration_values = smoothed\n\n    def compute_calibration_slopes(self):\n        self.calibration_slopes = np.array(\n            np.gradient(self.calibration_values, axis=0)\n        )  # TODO: Provide X values for the gradient\n\n    @staticmethod\n    def std_image(video):\n        \"\"\"\n        Compute the single video phase image\n        \"\"\"\n        std = np.std(video, axis=0)\n\n        # Get coordinates of the brightest pixel\n        bightest_pixel: tuple[int, int] = np.unravel_index(\n            np.argmax(std, axis=None), std.shape\n        )  # pyright: ignore\n\n        transposed_normalized_video = np.transpose(\n            video - np.mean(video, axis=0), (1, 2, 0)\n        )\n\n        brightest_pixel_time_trace = transposed_normalized_video[\n            bightest_pixel[0], bightest_pixel[1], :\n        ]\n\n        video_dot: np.ndarray = np.dot(\n            transposed_normalized_video, brightest_pixel_time_trace\n        )\n        return np.where(video_dot &gt; 0, std, -std)\n\n    ## Function that takes in an HDF5 file and returns a list of calibrated videos.\n    def compute_independant_video_images(self):\n        videos = (\n            self._file[\"stroboscopic\"][k][...]\n            for k in self._file[\"stroboscopic\"].keys()\n        )\n\n        specific_biases = [\n            self._file[\"stroboscopic\"][k].attrs[\"bias(V)\"]\n            for k in self._file[\"stroboscopic\"].keys()\n        ]\n\n        def find_nearest(array, value):\n            idx = np.searchsorted(array, value, side=\"left\")\n            if idx &gt; 0 and (\n                idx == len(array)\n                or np.abs(value - array[idx - 1]) &lt; np.abs(value - array[idx])\n            ):\n                return idx - 1\n            return idx\n\n        # Find the indices in calibration_* arrays corresponding to the videos\n        specific_biases_indices = np.array(\n            [\n                find_nearest(self.calibration_biases, specific_bias)\n                for specific_bias in specific_biases\n            ]\n        )\n        specific_biases_calibration_slope: np.ndarray = (\n            1 / self.calibration_slopes[specific_biases_indices, :, :]\n        )\n\n        std_images = np.array(\n            [\n                self.std_image(video)\n                for video in tqdm(\n                    videos,\n                    total=len(self._file[\"stroboscopic\"].keys()),\n                    desc=\"Processing videos\",\n                )\n            ]\n        )\n        print(\"Applying calibration sign...\", end=\"\")\n        std_images_phase_calibrated = std_images * np.where(\n            specific_biases_calibration_slope &gt; 0, 1, -1\n        )\n        std_images_full_calibrated = std_images * specific_biases_calibration_slope\n        print(\"Done\")\n        self.fully_calibrated_images = (\n            std_images_full_calibrated  # Phase+amplitude # TODO\n        )\n        self.phase_corrected_images = std_images_phase_calibrated  # phase only\n        self.calibration_slopes_video_indexed = self.calibration_slopes[\n            specific_biases_indices\n        ]\n\n    def combine_images(self):\n        \"\"\"\n        Combine images\n        \"\"\"\n        absolute_slopes = np.abs(self.calibration_slopes_video_indexed)\n        to_flip = np.array(\n            [\n                np.vdot(\n                    self.phase_corrected_images[0, :, :],\n                    self.phase_corrected_images[i, :, :],\n                )\n                for i in trange(0, self.phase_corrected_images.shape[0])\n            ]\n        )\n        corrected_photos: np.ndarray = np.where(\n            to_flip[:, None, None] &gt; 0,\n            self.fully_calibrated_images,\n            -self.fully_calibrated_images,\n        )\n\n        # Initialize empty images\n        self.mode_image = np.empty(corrected_photos.shape[1:])\n        self.best_video_index = np.empty(corrected_photos.shape[1:], dtype=np.uint64)\n        # For each pixel get the best video time trace\n        with np.nditer(\n            self.mode_image, flags=[\"multi_index\"], op_flags=[\"writeonly\"]\n        ) as it:\n            for pixel in tqdm(it, total=self.mode_image.size):\n                best_video = np.argmax(\n                    absolute_slopes[:, it.multi_index[0], it.multi_index[1]]\n                )\n                pixel[...] = corrected_photos[\n                    best_video, it.multi_index[0], it.multi_index[1]\n                ]\n                self.best_video_index[it.multi_index[0], it.multi_index[1]] = best_video\n</code></pre>"},{"location":"programs/python_module_reference/#strobing_interferometer.analysis.StdAnalysis.combine_images","title":"<code>combine_images()</code>","text":"<p>Combine images</p> Source code in <code>strobing_interferometer/analysis.py</code> <pre><code>def combine_images(self):\n    \"\"\"\n    Combine images\n    \"\"\"\n    absolute_slopes = np.abs(self.calibration_slopes_video_indexed)\n    to_flip = np.array(\n        [\n            np.vdot(\n                self.phase_corrected_images[0, :, :],\n                self.phase_corrected_images[i, :, :],\n            )\n            for i in trange(0, self.phase_corrected_images.shape[0])\n        ]\n    )\n    corrected_photos: np.ndarray = np.where(\n        to_flip[:, None, None] &gt; 0,\n        self.fully_calibrated_images,\n        -self.fully_calibrated_images,\n    )\n\n    # Initialize empty images\n    self.mode_image = np.empty(corrected_photos.shape[1:])\n    self.best_video_index = np.empty(corrected_photos.shape[1:], dtype=np.uint64)\n    # For each pixel get the best video time trace\n    with np.nditer(\n        self.mode_image, flags=[\"multi_index\"], op_flags=[\"writeonly\"]\n    ) as it:\n        for pixel in tqdm(it, total=self.mode_image.size):\n            best_video = np.argmax(\n                absolute_slopes[:, it.multi_index[0], it.multi_index[1]]\n            )\n            pixel[...] = corrected_photos[\n                best_video, it.multi_index[0], it.multi_index[1]\n            ]\n            self.best_video_index[it.multi_index[0], it.multi_index[1]] = best_video\n</code></pre>"},{"location":"programs/python_module_reference/#strobing_interferometer.analysis.StdAnalysis.smooth_calibration","title":"<code>smooth_calibration(window=np.array([0.1, 0.25, 0.3, 0.25, 0.1]))</code>","text":"<p>Smooth the calibration data points</p> Source code in <code>strobing_interferometer/analysis.py</code> <pre><code>def smooth_calibration(self, window=np.array([0.1, 0.25, 0.3, 0.25, 0.1])):\n    \"\"\"\n    Smooth the calibration data points\n    \"\"\"\n    if len(window.shape) &gt; 1:\n        raise ValueError(\"Smoothing kernel should be 1-dimensional\")\n\n    photos = self.get_calibration_photos()\n    biases = self.get_calibration_biases()\n    smoothed = np.apply_along_axis(\n        lambda x: np.convolve(window, x, mode=\"valid\"), axis=0, arr=photos\n    )\n    offset = window.size // 2  # number of values missing on each side\n\n    self.calibration_biases = biases[offset:-offset]\n    self.calibration_values = smoothed\n</code></pre>"},{"location":"programs/python_module_reference/#strobing_interferometer.analysis.StdAnalysis.std_image","title":"<code>std_image(video)</code>  <code>staticmethod</code>","text":"<p>Compute the single video phase image</p> Source code in <code>strobing_interferometer/analysis.py</code> <pre><code>@staticmethod\ndef std_image(video):\n    \"\"\"\n    Compute the single video phase image\n    \"\"\"\n    std = np.std(video, axis=0)\n\n    # Get coordinates of the brightest pixel\n    bightest_pixel: tuple[int, int] = np.unravel_index(\n        np.argmax(std, axis=None), std.shape\n    )  # pyright: ignore\n\n    transposed_normalized_video = np.transpose(\n        video - np.mean(video, axis=0), (1, 2, 0)\n    )\n\n    brightest_pixel_time_trace = transposed_normalized_video[\n        bightest_pixel[0], bightest_pixel[1], :\n    ]\n\n    video_dot: np.ndarray = np.dot(\n        transposed_normalized_video, brightest_pixel_time_trace\n    )\n    return np.where(video_dot &gt; 0, std, -std)\n</code></pre>"}]}